{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch\n",
    "!pip install pandas\n",
    "!pip install sentencepiece\n",
    "!pip install -U huggingface_hub\n",
    "!pip install tqdm\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "import transformers, torch\n",
    "from transformers import LlamaTokenizer,LlamaForCausalLM,GenerationConfig\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class data:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def load_data(self, url):\n",
    "        try:\n",
    "            df = pd.read_csv(url)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"load data failed:{e}\")\n",
    "            return None\n",
    "\n",
    "    def clean_data(self,df):\n",
    "        df = df.replace('\\n','').replace('\\r',' ')\n",
    "        #df =''.join(df.split())\n",
    "        return df.lower()\n",
    "\n",
    "    def clean_data2(self,df):\n",
    "        for column in ['description','transcription']:\n",
    "            df[column] = df[column].astype(str).apply(self.clean_data)\n",
    "        return df\n",
    "\n",
    "    def save_data(self,clean_df,url,):\n",
    "        new_file_name = r'mtsamples_cleaned.csv'\n",
    "        new_file_path = url.rsplit('\\\\', 1)[0] + '\\\\' + new_file_name\n",
    "        clean_df.to_csv(new_file_path, index=False)\n",
    "\n",
    "    def create_save(self):\n",
    "        file_path = r'/root/tf-logs/mtsamples.csv'\n",
    "        text = self.load_data(file_path)\n",
    "        clean_text = self.clean_data2(text)\n",
    "        #self.save_data(clean_text, file_path)\n",
    "        return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers, torch\n",
    "from transformers import LlamaTokenizer,LlamaForCausalLM,GenerationConfig\n",
    "import clean\n",
    "\n",
    "original_data = clean.data()\n",
    "cleaned_data = original_data.create_save()\n",
    "torch.cuda.empty_cache()\n",
    "limited_data = cleaned_data.head(100)\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"baffo32/decapoda-research-llama-7B-hf\")\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    \"baffo32/decapoda-research-llama-7B-hf\",\n",
    "    load_in_8bit=False,\n",
    "    torch_dtype=torch.float16\n",
    ").to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 初始化列表来保存结果\n",
    "patient_ages = []\n",
    "treatment_summaries = []\n",
    "\n",
    "# 循环遍历数据\n",
    "for index, row in tqdm(limited_data.iterrows(), total=limited_data.shape[0]):\n",
    "    text = f\"{row['description']} {row['transcription']}\"\n",
    "\n",
    "\n",
    "    age_prompt = f\"Question: What is the patient's age based on this text?\\n{text}\"\n",
    "    inputs = tokenizer(age_prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(model.device)\n",
    "    age_summary_ids = model.generate(**inputs, max_length=2000, num_beams=1, length_penalty=2.0, num_return_sequences=1, early_stopping=True)\n",
    "    age_summary = tokenizer.decode(age_summary_ids[0], skip_special_tokens=True)\n",
    "    patient_ages.append(age_summary)\n",
    "\n",
    "\n",
    "    treatment_prompt = f\"Summary: What patient treatment plan is contained in this text?\\n{text}\"\n",
    "    inputs = tokenizer(treatment_prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(model.device)\n",
    "    treatment_summary_ids = model.generate(**inputs, max_length=2000, num_beams=1, length_penalty=2.0, num_return_sequences=1, early_stopping=True)\n",
    "    treatment_summary = tokenizer.decode(treatment_summary_ids[0], skip_special_tokens=True)\n",
    "    treatment_summaries.append(treatment_summary)\n",
    "\n",
    "# 将结果保存到CSV文件\n",
    "results_df = pd.DataFrame({\n",
    "    'Patient Age': patient_ages,\n",
    "    'Treatment Plan': treatment_summaries\n",
    "})\n",
    "results_df.to_csv('llama1_summary_results_withoutrestriction.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
